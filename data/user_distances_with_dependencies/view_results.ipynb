{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04778572",
   "metadata": {},
   "source": [
    "# View New test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b051e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import the analyze_results module and necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def _flatten_dict(d, parent_key='', sep='_', include_complex=False):\n",
    "    \"\"\"Flatten nested dictionaries into a single level dictionary, \n",
    "    with option to include or skip complex nested structures like confusion matrices and classification reports\"\"\"\n",
    "    items = []\n",
    "    \n",
    "    # Keys to skip when include_complex=False\n",
    "    skip_keys = ['classification_report'] if not include_complex else []\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        \n",
    "        # Skip complex nested structures unless requested\n",
    "        if k in skip_keys:\n",
    "            continue\n",
    "            \n",
    "        if isinstance(v, dict):\n",
    "            # Only flatten simple dicts when include_complex=False, include all when True\n",
    "            if include_complex or all(not isinstance(val, (dict, list)) for val in v.values()):\n",
    "                items.extend(_flatten_dict(v, new_key, sep=sep, include_complex=include_complex).items())\n",
    "            else:\n",
    "                # For complex nested dicts, skip them when include_complex=False\n",
    "                continue\n",
    "        elif isinstance(v, list):\n",
    "            # Include lists when include_complex=True (like confusion matrices, outlier scores)\n",
    "            if include_complex:\n",
    "                items.append((new_key, v))\n",
    "            # Skip lists when include_complex=False\n",
    "        else:\n",
    "            # Include simple scalar values\n",
    "            items.append((new_key, v))\n",
    "            \n",
    "    return dict(items)\n",
    "\n",
    "def _safe_in_dict(d, key):\n",
    "    \"\"\"Helper to check if key is in dict and dict is not None\"\"\"\n",
    "    return isinstance(d, dict) and key in d\n",
    "\n",
    "def load_results(results_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Load results and flatten them into a pandas DataFrame where each row\n",
    "    represents a test method with flat (non-nested) columns.\n",
    "    \"\"\"\n",
    "    results_dir = Path(results_dir)\n",
    "    \n",
    "    if not results_dir.exists():\n",
    "        print(f\"Results directory {results_dir} not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Load individual seed results\n",
    "    seed_results = {}\n",
    "    for seed_file in results_dir.glob(\"*_comprehensive_results.json\"):\n",
    "        seed = seed_file.stem.split('_')[0]\n",
    "        try:\n",
    "            with open(seed_file, 'r') as f:\n",
    "                seed_results[seed] = json.load(f)\n",
    "            print(f\"✓ Loaded results from seed {seed}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error loading {seed_file}: {e}\")\n",
    "    \n",
    "    print(f\"✓ Loaded {len(seed_results)} seed results\")\n",
    "    \n",
    "    # Process and flatten the results into a DataFrame\n",
    "    flat_data = []\n",
    "    \n",
    "    for seed, data in seed_results.items():\n",
    "        \n",
    "        # Handle KNN results (nested by k and distance metric)\n",
    "        if 'knn_results' in data:\n",
    "            knn_data = data['knn_results']\n",
    "            for k_val, k_data in knn_data.items():\n",
    "                # Extract k value as integer (remove 'k' prefix)\n",
    "                k_num = int(k_val[1:]) if isinstance(k_val, str) and k_val.startswith('k') else k_val\n",
    "                \n",
    "                # Handle manifold results\n",
    "                if 'manifold' in k_data:\n",
    "                    row = {\n",
    "                        'seed': seed,\n",
    "                        'method': 'KNN-Manifold',\n",
    "                        'k': k_num,\n",
    "                    }\n",
    "                    # Add all metrics as flat columns, including confusion matrix\n",
    "                    manifold_metrics = k_data['manifold']\n",
    "                    for metric_name, metric_value in _flatten_dict(manifold_metrics, include_complex=True).items():\n",
    "                        row[metric_name] = metric_value\n",
    "                    \n",
    "                    # Add outlier scores if available\n",
    "                    outlier_scores = data.get('outlier_scores', None)\n",
    "                    if _safe_in_dict(outlier_scores, 'knn'):\n",
    "                        knn_outliers = outlier_scores['knn']\n",
    "                        if _safe_in_dict(knn_outliers, k_val) and _safe_in_dict(knn_outliers[k_val], 'manifold'):\n",
    "                            row['outlier_scores'] = knn_outliers[k_val]['manifold']\n",
    "                    \n",
    "                    flat_data.append(row)\n",
    "                \n",
    "                # Handle euclidean results  \n",
    "                if 'euclidean' in k_data:\n",
    "                    row = {\n",
    "                        'seed': seed,\n",
    "                        'method': 'KNN-Euclidean', \n",
    "                        'k': k_num,\n",
    "                    }\n",
    "                    # Add all metrics as flat columns, including confusion matrix\n",
    "                    euclidean_metrics = k_data['euclidean']\n",
    "                    for metric_name, metric_value in _flatten_dict(euclidean_metrics, include_complex=True).items():\n",
    "                        row[metric_name] = metric_value\n",
    "                    \n",
    "                    # Add outlier scores if available\n",
    "                    outlier_scores = data.get('outlier_scores', None)\n",
    "                    if _safe_in_dict(outlier_scores, 'knn'):\n",
    "                        knn_outliers = outlier_scores['knn']\n",
    "                        if _safe_in_dict(knn_outliers, k_val) and _safe_in_dict(knn_outliers[k_val], 'euclidean'):\n",
    "                            row['outlier_scores'] = knn_outliers[k_val]['euclidean']\n",
    "                    \n",
    "                    flat_data.append(row)\n",
    "        \n",
    "        # Handle PFGAP Euclidean results (no k values)\n",
    "        if 'pfgap_euclidean' in data:\n",
    "            row = {\n",
    "                'seed': seed,\n",
    "                'method': 'PFGAP-Euclidean',\n",
    "                'k': np.nan,  # No k for PFGAP methods\n",
    "            }\n",
    "            # Add all metrics as flat columns, including confusion matrix\n",
    "            for metric_name, metric_value in _flatten_dict(data['pfgap_euclidean'], include_complex=True).items():\n",
    "                row[metric_name] = metric_value\n",
    "            \n",
    "            # Add PFGAP outlier scores if available\n",
    "            outlier_scores = data.get('outlier_scores', None)\n",
    "            if _safe_in_dict(outlier_scores, 'pfgap'):\n",
    "                row['outlier_scores'] = outlier_scores['pfgap']\n",
    "            \n",
    "            flat_data.append(row)\n",
    "        \n",
    "        # Handle PFGAP Manifold results (future use, no k values)\n",
    "        if 'pfgap_manifold' in data:\n",
    "            row = {\n",
    "                'seed': seed,\n",
    "                'method': 'PFGAP-Manifold',\n",
    "                'k': np.nan,  # No k for PFGAP methods\n",
    "            }\n",
    "            # Add all metrics as flat columns, including confusion matrix\n",
    "            for metric_name, metric_value in _flatten_dict(data['pfgap_manifold'], include_complex=True).items():\n",
    "                row[metric_name] = metric_value\n",
    "            \n",
    "            # Add PFGAP outlier scores if available (assuming they'd be under pfgap_manifold in outlier_scores)\n",
    "            outlier_scores = data.get('outlier_scores', None)\n",
    "            if _safe_in_dict(outlier_scores, 'pfgap_manifold'):\n",
    "                row['outlier_scores'] = outlier_scores['pfgap_manifold']\n",
    "            \n",
    "            flat_data.append(row)\n",
    "    \n",
    "    # Create DataFrame from flattened data\n",
    "    results_df = pd.DataFrame(flat_data)\n",
    "    \n",
    "    # Convert seed to integer for better sorting/analysis\n",
    "    if not results_df.empty:\n",
    "        results_df['seed'] = results_df['seed'].astype(int)\n",
    "    \n",
    "    # Drop columns only if they exist\n",
    "    drop_cols = [\n",
    "        'classification_report_0_precision', 'classification_report_0_recall', 'classification_report_0_f1-score', 'classification_report_0_support',\n",
    "        'classification_report_1_precision', 'classification_report_1_recall', 'classification_report_1_f1-score', 'classification_report_1_support',\n",
    "        'classification_report_accuracy', 'classification_report_macro avg_precision', 'classification_report_macro avg_recall',\n",
    "        'classification_report_macro avg_f1-score', 'classification_report_macro avg_support', 'classification_report_weighted avg_precision',\n",
    "        'classification_report_weighted avg_recall', 'classification_report_weighted avg_f1-score', 'classification_report_weighted avg_support'\n",
    "    ]\n",
    "    cols_to_drop = [col for col in drop_cols if col in results_df.columns]\n",
    "    return results_df.drop(columns=cols_to_drop) if cols_to_drop else results_df\n",
    "\n",
    "# Set up matplotlib for inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn style for better plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e7ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded results from seed 456\n",
      "✓ Loaded results from seed 101112\n",
      "✓ Loaded results from seed 123\n",
      "✓ Loaded results from seed 42\n",
      "✓ Loaded results from seed 789\n",
      "✓ Loaded 5 seed results\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mload_results\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmolhiv_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mload_results\u001b[39m\u001b[34m(results_dir)\u001b[39m\n\u001b[32m    115\u001b[39m     row[metric_name] = metric_value\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Add outlier scores if available\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33moutlier_scores\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[33;43m'\u001b[39;49m\u001b[33;43mknn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutlier_scores\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m    119\u001b[39m     knn_outliers = data[\u001b[33m'\u001b[39m\u001b[33moutlier_scores\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mknn\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k_val \u001b[38;5;129;01min\u001b[39;00m knn_outliers \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m knn_outliers[k_val]:\n",
      "\u001b[31mTypeError\u001b[39m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "results = load_results(\"molhiv_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dce785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsimpute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
